{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 8 - The Machine Learning Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous weeks we have covered preprocessing our data, dimensionality reduction, clustering, regression and classification. This week we will be pulling these processes together into a complete project.\n",
    "\n",
    "Most projects can be thought of as a series of discrete steps:\n",
    "\n",
    "* Data acquisition / loading\n",
    "* Feature creation\n",
    "* Feature normalization\n",
    "* Feature selection\n",
    "* Machine learning model\n",
    "* Combining multiple models\n",
    "* Reporting / Utilization\n",
    "\n",
    "\n",
    "## Data acquisition\n",
    "\n",
    "If we are fortunate our data may already be in a usable format but more often extensive work is needed to generate something usable.\n",
    "\n",
    "* What type of data do we have?\n",
    "* Do we need to combine data from multiple sources?\n",
    "* Is our data structured in such a way it can be used directly?\n",
    "* Does our data need to be cleaned?\n",
    "* Does our data have issues with confounding?\n",
    "\n",
    "\n",
    "## Feature creation\n",
    "\n",
    "* Can our data be used directly?\n",
    "* What features have been used previously for similar tasks?\n",
    "\n",
    "\n",
    "## Feature normalization\n",
    "\n",
    "* Z-score normalization?\n",
    "* Min-max mormalization?\n",
    "\n",
    "\n",
    "## Feature selection\n",
    "\n",
    "The number of features we have compared with our sample size will determine whether feature selection is needed. We may choose in the first instance not to use feature selection. If we observe that our performance on the validation dataset is substantially worse than on the training dataset it is likely our model is overfitting and would benefit from limiting the number of features.\n",
    "\n",
    "Even if the performance is comparable we may still consider using dimensionality reduction or feature selection.\n",
    "\n",
    "\n",
    "## Machine learning model\n",
    "\n",
    "Which algorithm to use will depend on the type of task and the size of the dataset. As with the preceding steps it can be difficult to predict the optimal approach and different options should be tried.\n",
    "\n",
    "\n",
    "## Combining multiple models\n",
    "\n",
    "An additional step that can frequently boost performance is combining multiple different models. It is important to consider that although there are advantages combining different models can make the result more difficult to interpret.\n",
    "\n",
    "The models may be generated by using a different algorithm and/or different features.\n",
    "\n",
    "\n",
    "## Reporting / Utilization\n",
    "\n",
    "Finally we need to be able to utilize the model we have generated. This typically takes the form of receiving a new sample and then performing all the steps used in training to make a prediction. \n",
    "\n",
    "If we are generating a model only to understand the structure of the data we already have then the new samples may be the test dataset we set aside at the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rapid experimentation\n",
    "\n",
    "At each of the major steps we need to take there are a variety of options. It is often not clear which approach will give us the best performance and so we should try several.\n",
    "\n",
    "Being able to rapidly try different options helps us get to the best solution faster. It is tempting to make a change to our code, execute it, look at the performance, and then decide between sticking with the change or going back to the original version. It is very easy to:\n",
    "\n",
    "* Loose track of what code generated what solution\n",
    "* Overwrite a working solution and be unable to repeat it\n",
    "\n",
    "Using version control software is very useful for avoiding these issues.\n",
    "\n",
    "I introduced the resources below in week 2:\n",
    "\n",
    "The most popular version control software at the moment is [Git](http://www.git-scm.com/)\n",
    "\n",
    "There are a number of good tutorials available:\n",
    "\n",
    "* http://betterexplained.com/articles/a-visual-guide-to-version-control/\n",
    "* https://www.gitbook.com/book/gitbookio/progit\n",
    "* https://services.github.com/on-demand/\n",
    "* https://services.github.com/classnotes/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the entire workflow\n",
    "\n",
    "We have previously looked at approaches for choosing the optimal parameters for an algorithm. We also have choices earlier in the workflow that we should systematically explore - what features should we use, how should they be normalized, etc.\n",
    "\n",
    "There are multiple ways we can change our code to explore different approaches:\n",
    "\n",
    "* Commenting out sections\n",
    "* Wrapping functions around steps\n",
    "* Scikit-learn pipelines\n",
    "* Experimentation packages such as [sacred](https://github.com/IDSIA/sacred)\n",
    "\n",
    "We will try several approaches in the digits dataset using comments and functions before moving to the more advanced options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model, decomposition, datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "X_digits = digits.data\n",
    "y_digits = digits.target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = y_digits.shape[0]\n",
    "split = np.random.random(i)\n",
    "train = split < 0.7\n",
    "test = split >= 0.7\n",
    "X_digits_train = X_digits[train]\n",
    "X_digits_test = X_digits[test]\n",
    "y_digits_train = y_digits[train]\n",
    "y_digits_test = y_digits[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.958181818182\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.LogisticRegression()\n",
    "clf.fit(X_digits_train, y_digits_train)\n",
    "predictions = clf.predict(X_digits_test)\n",
    "print(accuracy_score(y_digits_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.554545454545\n"
     ]
    }
   ],
   "source": [
    "pca = decomposition.PCA()\n",
    "pca.fit(X_digits_train)\n",
    "#pca.transform(X_digits_train)[:,:2].shape\n",
    "\n",
    "z = 2\n",
    "clf = linear_model.LogisticRegression()\n",
    "clf.fit(pca.transform(X_digits_train)[:,:z], y_digits_train)\n",
    "predictions = clf.predict(pca.transform(X_digits_test)[:,:z])\n",
    "print(accuracy_score(y_digits_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit learn includes functionality for structuring our code and easily exploring the impact of different parameters not only in the machine learning algorithm we choose but at every stage of our solution.\n",
    "\n",
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/auto_examples/plot_digits_pipe.html#example-plot-digits-pipe-py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model, decomposition, datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "logistic = linear_model.LogisticRegression()\n",
    "\n",
    "pca = decomposition.PCA()\n",
    "pipe = Pipeline(steps=[('pca', pca), ('logistic', logistic)])\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "X_digits = digits.data\n",
    "y_digits = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x186d893d320>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEQCAYAAACugzM1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nM+uUE4WZmXXKicLMzDr1/wH2I6jGc9ETfwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x186d898d240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Plot the PCA spectrum\n",
    "pca.fit(X_digits)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(pca.explained_variance_, linewidth=2)\n",
    "ax.set_xlabel('n_components')\n",
    "ax.set_ylabel('explained_variance_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00000000e-04,   7.74263683e-04,   5.99484250e-03,\n",
       "         4.64158883e-02,   3.59381366e-01,   2.78255940e+00,\n",
       "         2.15443469e+01,   1.66810054e+02,   1.29154967e+03,\n",
       "         1.00000000e+04])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Prediction\n",
    "\n",
    "n_components = [20, 40, 64]\n",
    "Cs = np.logspace(-4, 4, 10)\n",
    "Cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# components: 40\n",
      "C: 2.78255940221\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=Pipeline(steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))]),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'logistic__C': array([  1.00000e-04,   7.74264e-04,   5.99484e-03,   4.64159e-02,\n",
      "         3.59381e-01,   2.78256e+00,   2.15443e+01,   1.66810e+02,\n",
      "         1.29155e+03,   1.00000e+04]), 'pca__n_components': [20, 40, 64]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "#Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "\n",
    "estimator = GridSearchCV(pipe,\n",
    "                         dict(pca__n_components=n_components,\n",
    "                              logistic__C=Cs))\n",
    "estimator.fit(X_digits, y_digits)\n",
    "\n",
    "print('# components:', estimator.best_estimator_.named_steps['pca'].n_components)\n",
    "print('C:', estimator.best_estimator_.named_steps['logistic'].C)\n",
    "\n",
    "print(estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA components: 2\n",
      "Original features used: 3\n",
      "C: 1\n",
      "Pipeline(steps=[('features', FeatureUnion(n_jobs=1,\n",
      "       transformer_list=[('pca', PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('univ_select', SelectKBest(k=3, score_func=<function f_classif at 0x00000186D83F4840>))],\n",
      "       transfo...,\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n"
     ]
    }
   ],
   "source": [
    "# http://scikit-learn.org/stable/auto_examples/feature_stacker.html#example-feature-stacker-py\n",
    "\n",
    "# Author: Andreas Mueller <amueller@ais.uni-bonn.de>\n",
    "#\n",
    "# License: BSD 3 clause\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# This dataset is way to high-dimensional. Better do PCA:\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Maybe some original features where good, too?\n",
    "selection = SelectKBest(k=1)\n",
    "\n",
    "# Build estimator from PCA and Univariate selection:\n",
    "\n",
    "combined_features = FeatureUnion([(\"pca\", pca), (\"univ_select\", selection)])\n",
    "\n",
    "# Use combined features to transform dataset:\n",
    "X_features = combined_features.fit(X, y).transform(X)\n",
    "\n",
    "svm = SVC(kernel=\"linear\")\n",
    "\n",
    "# Do grid search over k, n_components and C:\n",
    "\n",
    "pipeline = Pipeline([(\"features\", combined_features), (\"svm\", svm)])\n",
    "\n",
    "# numpy.arange, numpy.linspace, numpy.logspace, and range are all useful in creating options to evaluate\n",
    "param_grid = dict(features__pca__n_components=[1,2,3],\n",
    "                  features__univ_select__k=[1,2,3],\n",
    "                  svm__C=[0.1, 1, 10])\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid)\n",
    "grid_search.fit(X, y)\n",
    "print('PCA components:', grid_search.best_estimator_.named_steps['features'].get_params()['pca'].n_components)\n",
    "print('Original features used:', grid_search.best_estimator_.named_steps['features'].get_params()['univ_select'].k)\n",
    "print('C:', grid_search.best_estimator_.named_steps['svm'].C)\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text classification\n",
    "\n",
    "Working through an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['comp.graphics', 'sci.med']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train',\n",
    "    categories=['comp.graphics', 'sci.med'], shuffle=True, random_state=0)\n",
    "\n",
    "print(twenty_train.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: harti@mikro.ee.tu-berlin.de (Stefan Hartmann (Behse))\n",
      "Subject: Genoa graphics board Drivers FTP site!\n",
      "Article-I.D.: mailgzrz.1qpf1r$9ti\n",
      "Organization: TUBerlin/ZRZ\n",
      "Lines: 29\n",
      "NNTP-Posting-Host: mikro.ee.tu-berlin.de\n",
      "\n",
      "Hi,\n",
      "\n",
      "well I have opened up a FTP site for getting the latest software drivers\n",
      "for Genoa graphics cards.\n",
      "\n",
      "Here is how to access it:\n",
      "\n",
      "ftp 192.109.42.11\n",
      "login:ftp\n",
      "password:ftp\n",
      "cd pub/genoa\n",
      "ls -l\n",
      "binary\n",
      "prompt\n",
      "hash\n",
      "\n",
      "(now if you wanna have the latest drivers for the 7900 board)\n",
      "\n",
      "cd 7000series\n",
      "mget *\n",
      "\n",
      "quit\n",
      "\n",
      "This is the sequence to get the drivers.\n",
      "\n",
      "If you have any further question, please email me.\n",
      "\n",
      "Best regards, Stefan Hartmann\n",
      "email to: harti@mikro.ee.tu-berlin.de\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Looking at an example\n",
    "print(twenty_train.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1178x24614 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 170800 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first step is converting the text into numerical data we can work with\n",
    "# We will use a bag-of-words approach - counting the occurance of words\n",
    "from sklearn.feature_extraction.text import (CountVectorizer, \n",
    "                                             TfidfTransformer)\n",
    "\n",
    "# Using a pipeline \n",
    "pipe = Pipeline([('counts', CountVectorizer()), \n",
    "                 ('tfidf', TfidfTransformer())])\n",
    "\n",
    "output = pipe.fit(twenty_train.data).transform(twenty_train.data)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('counts', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        str...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'classifier__C': [0.1, 1, 10, 30, 100], 'counts__stop_words': [None, 'english'], 'counts__ngram_range': [(1, 1), (1, 2)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding a classifier\n",
    "\n",
    "pipe = Pipeline([('counts', CountVectorizer()), \n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('classifier', linear_model.LogisticRegression())])\n",
    "\n",
    "# We can compare different parameters at each stage\n",
    "param_grid = dict(counts__ngram_range=[(1,1), (1,2)],\n",
    "                  counts__stop_words=[None, 'english'],\n",
    "                  classifier__C=[0.1, 1, 10, 30, 100])\n",
    "\n",
    "X = twenty_train.data[:]\n",
    "y = twenty_train.target[:]\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid)\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of words: (1, 1)\n",
      "Stop words: english\n",
      "C: 10\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters\n",
    "\n",
    "print('# of words:', grid_search.best_estimator_.named_steps['counts'].ngram_range)\n",
    "print('Stop words:', grid_search.best_estimator_.named_steps['counts'].stop_words)\n",
    "print('C:', grid_search.best_estimator_.named_steps['classifier'].C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Pipeline: Seizure Detection\n",
    "\n",
    "In this example we will look at an EEG dataset with the goal of detecting the onset of epileptic seizures.\n",
    "\n",
    "This [machine learning task and associated dataset](https://www.kaggle.com/c/seizure-detection) was put together by UPenn and Mayo Clinic and hosted on Kaggle as a competition with financial backing from NINDS and the American Epilepsy Society.\n",
    "\n",
    "There are two parts to the data:\n",
    "\n",
    "* 16 electrode EEG at 400 Hz from dogs with naturally occurring epilepsy\n",
    "* Patient EEG recordings at 500 Hz and 5000 Hz with a variable number of electrodes\n",
    "\n",
    "There are a number of challenges in approaching this task.\n",
    "\n",
    "* Patient / animal specific differences\n",
    "* Different number of electrodes\n",
    "* Different sampling rates\n",
    "* Different electrode positions\n",
    "* Lack of existing features\n",
    "* . . . and likely several others\n",
    "\n",
    "### Data acquisition\n",
    "Thankfully with this being a Kaggle competition the data has already been collected for us. The data has been divided into multiple files each with 1 second of data. There are training examples for each of the subjects and samples have already been chosen for the test set.\n",
    "\n",
    "We will still want to perform validation but we can use Kaggle to measure our final performance on the test set.\n",
    "\n",
    "### Feature creation\n",
    "The data available are potentials observed by the different electrodes over the one second window used for each sample. These values are unlikely to be predictive in this format so we must use this data to create the features our model will use.\n",
    "\n",
    "This is the first real decision we need to make. What might our features be?\n",
    "\n",
    "\n",
    "### Feature normalization\n",
    "Applying normalization using standard approaches may be necessary depending on the algorithm we plan to use.\n",
    "\n",
    "\n",
    "### Feature selection\n",
    "The dataset is reasonably large and we are likely to have a limited number of features. Our first solution might not need to select features prior to building the model.\n",
    "\n",
    "Depending on how creative we get and how large the number of features we have grows later solutions may benefit from feature selection, either to prevent overfitting or to speed up evaluation.\n",
    "\n",
    "### Machine learning model\n",
    "Evaluating different algorithms as we build a solution is probably going to be the best approach. While we are developing features using an ensemble or boosting algorithm will be the simplest approach.\n",
    "\n",
    "### Combining multiple models\n",
    "There are multiple different levels at which we might develop machine learning models for this task. We could develop models for individual channels or all the channels combined. We could develop a single model for all subjects or separate models for each subject.\n",
    "\n",
    "All of these different models could then be combined together.\n",
    "\n",
    "### Reporting / Utilization\n",
    "For this task we know we will have a test dataset and our performance there will be evaluated.\n",
    "\n",
    "\n",
    "__NOTE:__ The dataset for this example is 43 GB uncompressed so I have not included it in the course material. If you want to run through the example it can be downloaded from the link above.\n",
    "\n",
    "A github repository with all the code for this example is [here](https://github.com/streety/kaggle-seizure-prediction).\n",
    "\n",
    "__NOTE #2:__ This example uses object-oriented programming and other relatively advanced approaches. \n",
    "\n",
    "__I do not expect you to follow this example fully at this stage in the course.__ \n",
    "\n",
    "To my knowledge, this is the most complex publicly available example of pipelines in scikit-learn.  I include this here as an example of how powerful this approach can be. During the competition, this model ranked in the top 15%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "\n",
    "class ModelTransformer(TransformerMixin):\n",
    "    \"\"\"Wrap a classifier model so that it can be used in a pipeline\"\"\"\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, *args, **kwargs):\n",
    "        self.model.fit(*args, **kwargs)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        return self.model.predict_proba(X)\n",
    "\n",
    "    def predict_proba(self, X, **transform_params):\n",
    "        return self.transform(X, **transform_params)\n",
    "\n",
    "\n",
    "class VarTransformer(TransformerMixin):\n",
    "    \"\"\"Compute the variance\"\"\"\n",
    "    def transform(self, X, **transform_params):\n",
    "        var = X.var(axis=1)\n",
    "        return var.reshape((var.shape[0],1))\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "\n",
    "class MedianTransformer(TransformerMixin):\n",
    "    \"\"\"Compute the median\"\"\"\n",
    "    def transform(self, X, **transform_params):\n",
    "        median = np.median(X, axis=1)\n",
    "        return median.reshape((median.shape[0],1))\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "class ChannelExtractor(TransformerMixin):\n",
    "    \"\"\"Extract a single channel for downstream processing\"\"\"\n",
    "    def __init__(self, channel):\n",
    "        self.channel = channel\n",
    "\n",
    "    def transform(self, X, **transformer_params):\n",
    "        return X[:,:,self.channel]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "\n",
    "class FFTTransformer(TransformerMixin):\n",
    "    \"\"\"Convert to the frequency domain and then sum over bins\"\"\"\n",
    "    def transform(self, X, **transformer_params):\n",
    "        fft = np.fft.rfft(X, axis=1)\n",
    "        fft = np.abs(fft)\n",
    "        fft = np.cumsum(fft, axis=1)\n",
    "        bin_size = 10\n",
    "        max_freq = 60\n",
    "        return np.column_stack([fft[:,i] - fft[:,i-bin_size] \n",
    "            for i in range(bin_size, max_freq, bin_size)])\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stree\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named 'get_traces'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-b60e3bf3131e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mget_traces\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtrans\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'get_traces'"
     ]
    }
   ],
   "source": [
    "\"\"\"This cell is not expected to run correctly. We don't have all the packages needed.\n",
    "\n",
    "If you want to run this example download the repository and the source data.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.cross_validation import cross_val_score, StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import get_traces\n",
    "import transformers as trans\n",
    "\n",
    "\n",
    "def build_pipeline(X):\n",
    "    \"\"\"Helper function to build the pipeline of feature transformations.\n",
    "    We do the same thing to each channel so rather than manually copying changes\n",
    "    for all channels this is automatically generated\"\"\"\n",
    "    channels = X.shape[2]\n",
    "    pipeline = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "            ('select_%d_pipeline' % i, \n",
    "                Pipeline([('select_%d' % i, trans.ChannelExtractor(i)),\n",
    "                ('channel features', FeatureUnion([\n",
    "                    ('var', trans.VarTransformer()),\n",
    "                    ('median', trans.MedianTransformer()),\n",
    "                    ('fft', trans.FFTTransformer()),\n",
    "                    ])),\n",
    "                ])\n",
    "            ) for i in range(channels)])),\n",
    "        ('classifier', trans.ModelTransformer(RandomForestClassifier(\n",
    "            n_estimators=500,\n",
    "            max_depth=None,\n",
    "            min_samples_split=1, \n",
    "            random_state=0))),\n",
    "            ])\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def get_transformed_data(patient, func=get_traces.get_training_traces):\n",
    "    \"\"\"Load in all the data\"\"\"\n",
    "    X = []\n",
    "    channels = get_traces.get_num_traces(patient)\n",
    "    # Reading in 43 Gb of data . . .\n",
    "    for i in range(channels):\n",
    "        x, y = func(patient, i)\n",
    "        X.append(x)\n",
    "    return (np.dstack(X), y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "all_labels = []\n",
    "all_predictions = np.array([])\n",
    "folders = [i for i in os.listdir(get_traces.directory) if i[0] != '.']\n",
    "folders.sort()\n",
    "for folder in folders:\n",
    "    print('Starting %s' % folder)\n",
    "\n",
    "    print('getting data')\n",
    "    X, y = get_transformed_data(folder)\n",
    "    print(X.shape)\n",
    "    print('stratifiedshufflesplit')\n",
    "    cv = StratifiedShuffleSplit(y,\n",
    "        n_iter=5,\n",
    "        test_size=0.2,\n",
    "        random_state=0,)\n",
    "    print('cross_val_score')\n",
    "    \n",
    "    pipeline = build_pipeline(X)\n",
    "    \n",
    "    # Putting this in a list is unnecessary for just one pipeline - use to compare multiple pipelines\n",
    "    scores = [\n",
    "        cross_val_score(pipeline, X, y, cv=cv, scoring='roc_auc')\n",
    "        ]\n",
    "    print('displaying results')\n",
    "    for score, label in zip(scores, ['pipeline',]):\n",
    "        print(\"AUC:  {:.2%} (+/- {:.2%}), {:}\".format(score.mean(), \n",
    "            score.std(), label))\n",
    "    \n",
    "    clf = pipeline\n",
    "    print('Fitting full model')\n",
    "    clf.fit(X, y)\n",
    "    print('Getting test data')\n",
    "    testing_data, files = get_transformed_data(folder, \n",
    "            get_traces.get_testing_traces)\n",
    "    print('Generating predictions')\n",
    "    predictions = clf.predict_proba(testing_data)\n",
    "    print(predictions.shape, len(files))\n",
    "    with open('%s_randomforest_predictions.pkl' % folder, 'wb') as f:\n",
    "        pickle.dump((files, predictions[:,1]), f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving a model\n",
    "\n",
    "The final step is using our trained model. This might be in a research article or as part of an ongoing service. In either case we want to be able to save a version of our model. We can use the saved model to address reviewers comments, to move the model to a production server, etc.\n",
    "\n",
    "Scikit learn models can be saved by using the pickle storage package and the joblib variant which is more efficient in handling numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10)\n",
      "(442,)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 442 entries, 0 to 441\n",
      "Data columns (total 10 columns):\n",
      "age    442 non-null float64\n",
      "sex    442 non-null float64\n",
      "bmi    442 non-null float64\n",
      "map    442 non-null float64\n",
      "tc     442 non-null float64\n",
      "ldl    442 non-null float64\n",
      "hdl    442 non-null float64\n",
      "tch    442 non-null float64\n",
      "ltg    442 non-null float64\n",
      "glu    442 non-null float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 34.6 KB\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "# Description at http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
    "# Ten baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements\n",
    "# were obtained for each of n = 442 diabetes patients,\n",
    "# as well as the response of interest, a quantitative measure of disease progression one year after baseline.\n",
    "\n",
    "X = diabetes.data     # independent variables\n",
    "y = diabetes.target   # dependent val\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.DataFrame(X, columns=['age', 'sex', 'bmi', 'map', \n",
    "                                'tc', 'ldl', 'hdl', 'tch', 'ltg', 'glu'])\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x186df5f39e8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEPCAYAAABRHfM8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noljx/wFxwQrL125bkwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x186df5ea828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "bmi = X[:, 2].reshape(-1, 1)\n",
    "outcome = y\n",
    "\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(bmi, outcome)\n",
    "predicted_outcome = reg.predict(bmi)\n",
    "\n",
    "plt.plot(predicted_outcome, outcome, 'k.')\n",
    "plt.xlabel(\"Predicted outcome\")\n",
    "plt.ylabel(\"Clinical outcome\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directly trained model predictions: [ 210.71003806  103.26219543  194.33703347  141.12476855  117.58857445\n",
      "  113.4953233   107.35544658  150.33458363  210.71003806  189.22046954]\n",
      "Saved model predictions: [ 210.71003806  103.26219543  194.33703347  141.12476855  117.58857445\n",
      "  113.4953233   107.35544658  150.33458363  210.71003806  189.22046954]\n"
     ]
    }
   ],
   "source": [
    "print('Directly trained model predictions:', predicted_outcome[:10])\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(reg, 'diabetes_prediction_model.pkl')\n",
    "\n",
    "reg2 = joblib.load('diabetes_prediction_model.pkl') \n",
    "predicted_outcome2 = reg2.predict(bmi)\n",
    "print('Saved model predictions:', predicted_outcome[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. The diabetes example above currently only uses BMI. Expand it to include the other variables.\n",
    "2. Convert the model over to a pipeline format. *This pipeline will only have one element at this stage - you will build it up in the next exercises.* Do you get the same predictions?\n",
    "3. Create a new pipeline applying PCA to the dataset before the classifier. What is the optimal number of dimensions? *Try 10-20 options spanning the entire range of 1-64*\n",
    "4. Build a pipeline using a different algorithm. For example, try k-nearest neighbor or random forest regressor. What are the optimal parameters for you chosen model?\n",
    "5. Looking at both models is the size of the errors (residuals) randomly distributed across the range of the outcome variable or is there a pattern? For example, perhaps the models underestimate at high outcome values? These types of pattern are strong indicators that a model can be improved further by creating new features or combining different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
